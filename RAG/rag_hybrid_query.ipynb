{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG Hybrid search\n",
    "\n",
    "This notebook shows how a hybrid search (vector search + keyword search) can be performed using RAG components.  The following frameworks and DB libraries are used to build this search:\n",
    "\n",
    "1. LlamaIndex - for hybrid search\n",
    "2. ChromaDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import chromadb\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resource module not available on Windows\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
    "\n",
    "from llama_index.core import (\n",
    "    SimpleDirectoryReader, \n",
    "    VectorStoreIndex, \n",
    "    Settings\n",
    ")\n",
    "\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.retrievers.bm25 import BM25Retriever\n",
    "from llama_index.core.retrievers import QueryFusionRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_VERSION\"] = os.getenv(\"OPENAI_API_VERSION\")\n",
    "os.environ[\"OPENAI_API_BASE\"] = os.getenv(\"OPENAI_API_BASE\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define LLM and Embedding models.  These are required for RAG operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureOpenAI(\n",
    "    engine = \"<engine name>\",\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0.0,\n",
    "    azure_endpoint = os.environ['OPENAI_API_BASE'],\n",
    "    api_key = os.environ['OPENAI_API_KEY'],\n",
    "    api_version = os.environ['OPENAI_API_VERSION'],\n",
    ")\n",
    "\n",
    "embed_model = AzureOpenAIEmbedding (\n",
    "    model = \"text-embedding-ada-002\",\n",
    "    deployment_name= \"<deployment name>\",\n",
    "    azure_endpoint = os.environ['OPENAI_API_BASE'],\n",
    "    api_key = os.environ['OPENAI_API_KEY'],\n",
    "    api_version = os.environ['OPENAI_API_VERSION'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load external data and index it\n",
    "\n",
    "we are going to use a smaller chunk size (256). Typically, this results in a better accuracy for search operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86f3d050469545f9a9e1c22c8087e152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd29718150a84d80ac561536f9e2d6af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/68 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = SimpleDirectoryReader(input_files=[\"gs_MA_report.pdf\"]).load_data()\n",
    "splitter = SentenceSplitter(chunk_size=256)\n",
    "nodes = splitter.get_nodes_from_documents(data)\n",
    "\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    data, \n",
    "    transformations=[splitter], \n",
    "    show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining both vector and BM25 retrievers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_retriever = index.as_retriever(similarity_top_k=5)\n",
    "\n",
    "bm25_retriever = BM25Retriever.from_defaults(\n",
    "    nodes=nodes,\n",
    "    similarity_top_k=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Hybrid Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = QueryFusionRetriever(\n",
    "    [vector_retriever, bm25_retriever],\n",
    "    retriever_weights=[0.6, 0.4],\n",
    "    similarity_top_k=10,\n",
    "    num_queries=1,  # to disable query generation\n",
    "    mode=\"relative_score\",\n",
    "    use_async=True,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Query Engine and run RAG hybrid queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = RetrieverQueryEngine.from_args(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI is expected to unlock efficiencies that could be deflationary and potentially disruptive for some SaaS companies, pushing down valuations and, in certain cases, driving them to go private. Conversely, software companies with entrenched customer relationships and proprietary datasets are likely to become key targets for AI transformation, leading to solid M&A outcomes.\n",
      "CPU times: total: 219 ms\n",
      "Wall time: 1.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "query_ai = \"what is the effect of GenAI in M&A in the year 2025\"\n",
    "response = query_engine.query(query_ai)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
